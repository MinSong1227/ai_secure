{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "프로젝트_화이팅.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x4vVDVDs_ZA",
        "outputId": "366665f6-9c5a-466e-cec5-30b5f15191ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55tTXGJDvWo6"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/데이터.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwqqnh3Om28q"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pprint\n",
        "import pandas\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZIkg4n7m29e"
      },
      "source": [
        "SEED = 41\n",
        "\n",
        "def read_label_csv(path):\n",
        "    label_table = dict()\n",
        "    with open(path, \"r\", encoding= \"cp949\") as f:\n",
        "        for line in f.readlines()[1:]:\n",
        "            fname, label = line.strip().split(\",\")\n",
        "            label_table[fname] = int(label)\n",
        "    return label_table\n",
        "\n",
        "def read_json(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def load_model(**kwargs):\n",
        "    if kwargs[\"model\"] == \"rf\":\n",
        "        return RandomForestClassifier(random_state=kwargs[\"random_state\"], n_jobs=4)\n",
        "    elif kwargs[\"model\"] == \"dt\":\n",
        "        return DecisionTreeClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lgb\":\n",
        "        return LGBMClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"svm\":\n",
        "        return SVC(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lr\":\n",
        "        return LogisticRegression(random_state=kwargs[\"random_state\"], n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"knn\":\n",
        "        return KNeighborsClassifier(n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"adaboost\":\n",
        "        return AdaBoostClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"mlp\":\n",
        "        return MLPClassifier(random_state=kwargs[\"random_state\"])\n",
        "    else:\n",
        "        print(\"Unsupported Algorithm\")\n",
        "        return None\n",
        "    \n",
        "\n",
        "def train(X_train, y_train, model):\n",
        "    clf = load_model(model=model, random_state=SEED)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def evaluate(X_test, y_test, model):\n",
        "    predict = model.predict(X_test)\n",
        "    print(\"정확도\", model.score(X_test, y_test))\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7Ml1Kb8m29z"
      },
      "source": [
        "## 레이블 테이블 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUwhF5Kpm293"
      },
      "source": [
        "label_table = read_label_csv(\"학습데이터_정답.csv\")\n",
        "label_table1 = read_label_csv(\"검증데이터_정답.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVFs8_zRm2-N"
      },
      "source": [
        "## 특징 벡터 생성 예시\n",
        "- PEMINER 정보는 모두 수치형 데이터이므로 특별히 가공을 하지 않고 사용 가능\n",
        "- EMBER, PESTUDIO 정보는 가공해서 사용해야 할 특징들이 있음 (e.g. imports, exports 등의 문자열 정보를 가지는 데이터)\n",
        "- 수치형 데이터가 아닌 데이터(범주형 데이터)를 어떻게 가공할 지가 관건 >> 인코딩 (e.g. 원핫인코딩, 레이블인코딩 등)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgWU_lEAm2_D"
      },
      "source": [
        "class PeminerParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "\n",
        "    ## PEminer 피처는 모두 등록하여 사용\n",
        "    def process_report(self):        \n",
        "\n",
        "        self.vector = [value for _, value in sorted(self.report.items(), key=lambda x: x[0])]\n",
        "        return self.vector\n",
        "        \n",
        "\n",
        "class EmberParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def get_histogram_info(self):\n",
        "        histogram = np.array(self.report[\"histogram\"])\n",
        "        total = histogram.sum()\n",
        "        vector = histogram / total\n",
        "        return vector.tolist()\n",
        "\n",
        "    # selection 내에  값들 중 entropy가 6이 넘는 값들을 기록함\n",
        "    def get_section_info(self):\n",
        "      entropys = []\n",
        "      strings = self.report[\"section\"]\n",
        "      temp = 0\n",
        "      for i in range(len(strings[\"sections\"])):\n",
        "        temp = max(temp,strings[\"sections\"][i][\"entropy\"])\n",
        "      if(temp >= 6.0):\n",
        "        entropys.append(temp)\n",
        "      else:\n",
        "        entropys.append(0)\n",
        "      return entropys\n",
        "\n",
        "      \n",
        "\n",
        "    def get_string_info(self):\n",
        "        strings = self.report[\"strings\"]\n",
        "\n",
        "        hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0\n",
        "        vector = [\n",
        "            strings['numstrings'], \n",
        "            strings['avlength'], \n",
        "            strings['printables'],\n",
        "            strings['entropy'], \n",
        "            strings['paths'], \n",
        "            strings['urls'],\n",
        "            strings['registry'], \n",
        "            strings['MZ']\n",
        "        ]\n",
        "        vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()\n",
        "        return vector\n",
        "    \n",
        "    def get_general_file_info(self):\n",
        "        general = self.report[\"general\"]\n",
        "\n",
        "        vector = [\n",
        "            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],\n",
        "            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],\n",
        "            general['symbols']\n",
        "        ]\n",
        "        return vector\n",
        "    # inport된 라이브러리 갯수를 모두 더해서 비교\n",
        "    def import_info(self):\n",
        "      imports = self.report[\"imports\"]\n",
        "      count = 0\n",
        "      for i in imports:\n",
        "        count = count + 1\n",
        "      return [count]\n",
        "\n",
        "\n",
        "    # inport된 라이브러리 갯수를 모두 더해서 비교\n",
        "    def import_info2(self):\n",
        "      vector = []\n",
        "      total = len(self.report['imports'])\n",
        "      vector.append(total)\n",
        "      return vector\n",
        "\n",
        "    # datadirectories 안에 있는 데이터들의 입력이 400000 스택영역으로 들어가는지 확인\n",
        "    def data_direc(self):\n",
        "      dir = self.report[\"datadirectories\"]\n",
        "      if dir['virtual_address'] > 400000:\n",
        "        key = 1\n",
        "      else:\n",
        "        key = 0\n",
        "      vector = [\n",
        "          dir['size'], dir['virtual_address']\n",
        "      ]\n",
        "      return vector\n",
        "\n",
        "    # byteentropy가 10 이상인 횟수를 추출하여 문서가 전체적으로 난수화 되어있는지 확인\n",
        "    def get_byte_entropy(self):\n",
        "      entro = self.report[\"byteentropy\"]\n",
        "      count = 0        \n",
        "      for i in entro:\n",
        "        if i > 6.0:\n",
        "          count += 1\n",
        "        \n",
        "      return [count]\n",
        "\n",
        "    # byteentropy 가 작은건 작게 큰건 매우 크게 만들어 크기 차이로 머신러닝을 효과적으로 하기 위해 bytebyteentropyentropy를 제곱해서 저장\n",
        "    def get_byte_entropy2(self):\n",
        "      byteentropys = np.array(self.report[\"byteentropy\"])\n",
        "      sqrt = np.exp(byteentropys)\n",
        "      vector = sqrt /10\n",
        "      return byteentropys.tolist()\n",
        "\n",
        "    # byteentropy의 값이 많기때문에 중위값으로 대표값을 설정하여 저장\n",
        "    def get_byte_entropy3(self):\n",
        "       byteentropys = np.array(self.report[\"byteentropy\"])\n",
        "       vector = []\n",
        "       vector.append(np.median(byteentropys))\n",
        "       return vector\n",
        "\n",
        "    # byteentropy의 값이 제일 큰거 11개만\n",
        "    def get_byte_entropy4(self):\n",
        "       bytee = np.array(self.report[\"byteentropy\"])\n",
        "       a = bytee.tolist()\n",
        "       a.sort(reverse=True)\n",
        "       vector = []\n",
        "       \n",
        "       for i in range(0,11):\n",
        "        vector.append(a[i])\n",
        "       return vector       \n",
        "\n",
        "    #여러가지 만들어 시도해봤지만.. 모두 정확도를 낮추기만해서 제거\n",
        "    def process_report(self):\n",
        "        vector = []\n",
        "        vector += self.get_general_file_info()\n",
        "        vector += self.get_histogram_info()\n",
        "        vector += self.get_string_info()\n",
        "        vector += self.get_byte_entropy4()\n",
        "        # vector += self.get_byte_entropy4()\n",
        "        # vector += self.import_info2()\n",
        "        # vector += self.data_direc()\n",
        "        # vector += self.import_info()\n",
        "        # vector += self.get_section_info()\n",
        "        # vector += self.get_byte_entropy()\n",
        "\n",
        "        return vector"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMdHYWl9m2_P"
      },
      "source": [
        "## 학습데이터 구성\n",
        "- 특징 벡터 구성은 2차원이 되어야함 e.g.  [vector_1, vector_2, ..., vector_n]\n",
        "\n",
        "- 각 벡터는 1차원 리스트, 벡터 크기는 모두 같아야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9zj-S7dm2_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e778178-a1f8-4e81-e8d0-f74178f0f741"
      },
      "source": [
        "# 데이터의 특징 벡터 모음(2차원 리스트) : X(학습데이터) , x_validation(검증데이터)\n",
        "# 데이터의 레이블 모음(1차원 리스트) : y(학습데이터) , y_validation(검증데이터)\n",
        "X, y = [], []\n",
        "x_validation, y_validation = [],[]\n",
        "file_list = os.listdir(\"EMBER/학습데이터\")\n",
        "file_list2 = os.listdir(\"EMBER/검증데이터\")\n",
        "k=[]\n",
        "m=[]\n",
        "for a in file_list:\n",
        "\tk.append(a.replace('.json',''))\n",
        "\n",
        "for b in file_list2:\n",
        "  m.append(b.replace('.json',''))\n",
        "\n",
        "\n",
        "for fname in k:\n",
        "     feature_vector = []\n",
        "     \n",
        "     label = label_table[str(fname)]\n",
        "     for data in [\"PEMINER\", \"EMBER\"]:\n",
        "         path = f\"{data}/학습데이터/{fname}.json\"\n",
        "         if data == \"PEMINER\":\n",
        "             feature_vector += PeminerParser(path).process_report()\n",
        "         else:\n",
        "             feature_vector += EmberParser(path).process_report()\n",
        "\n",
        "     X.append(feature_vector)\n",
        "     y.append(label)\n",
        "\n",
        "for fname in m:\n",
        "     feature_vector1=[]\n",
        "     label = label_table1[str(fname)]\n",
        "\n",
        "     for data in [\"PEMINER\", \"EMBER\"]:\n",
        "       path = f\"{data}/검증데이터/{fname}.json\"\n",
        "       if data == \"PEMINER\":\n",
        "         feature_vector1 += PeminerParser(path).process_report()\n",
        "       else:\n",
        "         feature_vector1 += EmberParser(path).process_report()\n",
        "\n",
        "     x_validation.append(feature_vector1)\n",
        "     y_validation.append(label)\n",
        "\n",
        "print(np.asarray(X).shape, np.asarray(y).shape)\n",
        "np.asarray(x_validation).shape, np.asarray(y_validation).shape\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 569) (20000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 569), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mln0AaaWm2_e"
      },
      "source": [
        "## 학습 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyzIJr7hm2_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5dd9db-db66-4fba-d8fb-e78c2ff3202b"
      },
      "source": [
        "# 학습데이터로 학습\n",
        "models = []\n",
        "for model in [\"rf\",\"lgb\"]:\n",
        "    clf = train(X, y, model)\n",
        "    models.append(clf)\n",
        "\n",
        "\n",
        "# 학습데이터로 학습된 모델을 통해 검증\n",
        "for model in models:\n",
        "    evaluate(x_validation, y_validation, model)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9426\n",
            "정확도 0.954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7tWjSqFm2_n"
      },
      "source": [
        "## 앙상블 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grpD-1_em2_p"
      },
      "source": [
        "def ensemble_result(X, y, models):\n",
        "    '''\n",
        "        학습된 모델들의 결과를 앙상블하는 함수\n",
        "\t\n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param models: 1개 이상의 학습된 머신러닝 모델 객체를 가지는 1차원 리스트\n",
        "    '''\n",
        " \n",
        "    # Soft Voting\n",
        "    # https://devkor.tistory.com/entry/Soft-Voting-%EA%B3%BC-Hard-Voting\n",
        "    predicts = []\n",
        "    for model in models:\n",
        "        prob = [result for _, result in model.predict_proba(X)]\n",
        "        predicts.append(prob)\n",
        "    \n",
        "    predict = np.mean(predicts, axis=0)\n",
        "    predict = [1 if x >= 0.5 else 0 for x in predict]\n",
        "\n",
        "        \n",
        "    print(\"정확도\", accuracy_score(y, predict))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTYlJAcBm2_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7628ebb8-d505-4cbe-bfa3-307d064264d8"
      },
      "source": [
        "ensemble_result(x_validation, y_validation, models)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eJNVzMuitl_"
      },
      "source": [
        "검증데이터로 추가 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4J4cmB9isMW"
      },
      "source": [
        "\n",
        "#모델에 검증데이터로 추가 학습\n",
        "for model in [\"rf\",\"lgb\"]:\n",
        "    clf = train(x_validation, y_validation, model)\n",
        "    models.append(clf)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rac2BuSS6r-v"
      },
      "source": [
        "# 테스트 데이터 예측 결과 파일 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gsy9y9I6kdf"
      },
      "source": [
        "def ensemble_result_predict_csv():\n",
        "    fin=[]\n",
        "    file_list2 = os.listdir(\"EMBER/테스트데이터\")\n",
        "    o=[]\n",
        "    for a in file_list2:\n",
        "      o.append(a.replace('.json',''))\n",
        "\n",
        "    for fname in o:\n",
        "     feature_vector2=[]\n",
        "\n",
        "     for data in [\"PEMINER\", \"EMBER\"]:\n",
        "       path = f\"{data}/테스트데이터/{fname}.json\"\n",
        "       if data == \"PEMINER\":\n",
        "         feature_vector2 += PeminerParser(path).process_report()\n",
        "       else:\n",
        "         feature_vector2 += EmberParser(path).process_report()\n",
        "\n",
        "     fin.append(feature_vector2)\n",
        "\n",
        "    predicts = []\n",
        "    for model in models:\n",
        "        prob = [result for _, result in model.predict_proba(fin)]\n",
        "        predicts.append(prob)\n",
        "    \n",
        "    predict = np.mean(predicts, axis=0)\n",
        "    predict = [1 if x >= 0.5 else 0 for x in predict]\n",
        "\n",
        "\n",
        "    f = open('predict.csv', 'w', encoding='cp949')\n",
        "    wr = csv.writer(f)\n",
        "    wr.writerow([\"file\",\"predict\"])\n",
        "    for i in range(len(o)):\n",
        "      wr.writerow([o[i],predict[i]])\n",
        "    f.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21tkvDOcFPgg"
      },
      "source": [
        "ensemble_result_predict_csv()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy_ILV1gjaJw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}